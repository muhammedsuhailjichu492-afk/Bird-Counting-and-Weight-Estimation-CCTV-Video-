# Poultry Monitoring System

A comprehensive computer vision system for automated poultry monitoring with bird counting, tracking, and weight estimation from fixed-camera CCTV footage.

## üìã Table of Contents

- [Features](#features)
- [System Requirements](#system-requirements)
- [Installation](#installation)
- [Quick Start](#quick-start)
- [Implementation Details](#implementation-details)
- [API Documentation](#api-documentation)
- [Usage Examples](#usage-examples)
- [Troubleshooting](#troubleshooting)
- [Performance Optimization](#performance-optimization)

## ‚ú® Features

### ‚úÖ Bird Counting (Mandatory)
- **Detection**: YOLOv8 pretrained on COCO (bird class)
- **Tracking**: ByteTrack algorithm with stable ID assignment
- **Output**: Time-series of bird counts with timestamps
- **Anti-double-counting**: Minimum track length filtering + stable IDs
- **Occlusion Handling**: Motion prediction + lost track buffer (30 frames)

### ‚úÖ Weight Estimation (Mandatory)
- **Method**: Feature-based regression using bounding box area and aspect ratio
- **Output**: Weight proxy (relative index) or calibrated grams
- **Per-bird Tracking**: Individual weight estimates with confidence scores
- **Temporal Smoothing**: Averaged over track lifetime for stability

### ‚úÖ Artifacts
- Annotated video with bounding boxes, tracking IDs, and count overlay
- JSON results with counts, tracks, and weight estimates
- Comprehensive metadata and statistics

## üñ•Ô∏è System Requirements

**Minimum:**
- Python 3.8+
- 4GB RAM
- CPU processing (slower)

**Recommended:**
- Python 3.9+
- 8GB+ RAM
- GPU with CUDA (10x faster)
- 2GB+ disk space for models

## üì¶ Installation

### Step 1: Create Virtual Environment

```bash
# Create virtual environment
python -m venv venv

# Activate (Linux/Mac)
source venv/bin/activate

# Activate (Windows)
venv\Scripts\activate
```

### Step 2: Install Dependencies

```bash
# Install all required packages
pip install -r requirements.txt
```

The system will automatically download YOLOv8 model weights on first run (~6MB).

### Step 3: Verify Installation

```bash
# Check Python packages
pip list | grep -E "fastapi|ultralytics|opencv"

# Expected output:
# fastapi==0.104.1
# ultralytics==8.0.221
# opencv-python==4.8.1.78
```

## üöÄ Quick Start

### 1. Start the API Server

```bash
# Using uvicorn directly
uvicorn main:app --reload --host 0.0.0.0 --port 8000

# Or run the Python file
python main.py
```

The API will be available at `http://localhost:8000`

**Expected output:**
```
INFO:     Started server process
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8000
```

### 2. Test the Health Endpoint

```bash
curl http://localhost:8000/health
```

**Response:**
```json
{
  "status": "OK",
  "service": "Poultry Monitoring System"
}
```

### 3. Analyze a Video

**Using cURL:**
```bash
curl -X POST "http://localhost:8000/analyze_video" \
  -F "file=@poultry_video.mp4" \
  -F "fps_sample=5" \
  -F "conf_thresh=0.25" \
  -F "iou_thresh=0.45"
```

**Using Python client:**
```bash
python test_client.py --video poultry_video.mp4 --fps 5 --output ./results
```

**Using requests library:**
```python
import requests

with open('poultry_video.mp4', 'rb') as f:
    files = {'file': ('video.mp4', f, 'video/mp4')}
    data = {
        'fps_sample': 5,
        'conf_thresh': 0.25,
        'iou_thresh': 0.45
    }
    response = requests.post(
        'http://localhost:8000/analyze_video',
        files=files,
        data=data
    )
    results = response.json()
    print(f"Unique birds tracked: {results['metadata']['unique_tracks']}")
    print(f"Average count: {results['metadata']['avg_bird_count']}")
```

## üî¨ Implementation Details

### Bird Counting Method

**Detection + Tracking Pipeline:**

```
Video Input
    ‚Üì
Frame Sampling (optional FPS reduction)
    ‚Üì
YOLOv8 Detection (bird class, conf_thresh)
    ‚Üì
ByteTrack Assignment
    ‚îú‚îÄ‚Üí New tracks (activation threshold: 0.25)
    ‚îú‚îÄ‚Üí Matched tracks (motion prediction)
    ‚îî‚îÄ‚Üí Lost tracks (buffer: 30 frames)
    ‚Üì
Track Filtering (min length: 5 frames)
    ‚Üì
Count Aggregation
```

**Key Components:**

1. **YOLOv8 Detection**
   - Uses pretrained YOLOv8n (nano) model on COCO dataset
   - Filters for bird class (class_id = 14)
   - Configurable confidence threshold (default: 0.25)
   - Non-maximum suppression with IoU threshold (default: 0.45)

2. **ByteTrack Tracking**
   - State-of-the-art multi-object tracker
   - Assigns stable IDs across frames
   - Handles occlusions through motion prediction
   - Parameters:
     - `track_activation_threshold`: 0.25 (prevents spurious detections)
     - `lost_track_buffer`: 30 frames (maintains IDs during brief occlusions)
     - `minimum_matching_threshold`: 0.8 (high IoU for reliable matching)
     - `minimum_consecutive_frames`: 5 (filters transient false positives)

3. **Anti-Double-Counting Mechanisms**
   - **Stable Tracking IDs**: Each bird receives unique ID maintained across frames
   - **Track Activation Threshold**: Only confident detections create new tracks
   - **Minimum Track Length**: Filters tracks < 5 frames (likely false positives)
   - **Temporal Consistency**: Counts unique track IDs per frame

4. **Occlusion Handling**
   - **Motion Prediction**: Predicts bird position during brief occlusions
   - **Lost Track Buffer**: Maintains track IDs for 30 frames after last detection
   - **High Matching Threshold**: 0.8 IoU reduces false matches during re-identification

**Example Scenario:**
```
Frame 100: Bird detected (ID=5)
Frame 101-103: Bird occluded by another bird
  ‚Üí Tracker predicts position, maintains ID=5
Frame 104: Bird reappears
  ‚Üí Successfully matched to ID=5 (no new ID created)
```

### Weight Estimation Approach

**Method: Feature-Based Regression**

The system uses bounding box geometry as a proxy for bird weight. This approach is based on the assumption that larger birds occupy more pixels in a fixed-camera setup.

**Formula:**
```python
weight_index = bbox_area √ó density_factor √ó (1 + 0.1 √ó aspect_ratio)

where:
- bbox_area = (x2 - x1) √ó (y2 - y1)  # pixels
- density_factor = 1.0  # baseline (can be calibrated)
- aspect_ratio = height / width  # body shape information
```

**Confidence Calculation:**
```python
size_confidence = min(bbox_area / 5000, 1.0)
final_confidence = detection_conf √ó size_confidence √ó 0.8
```

**Temporal Smoothing:**
- Weight estimates are averaged over the bird's entire track lifetime
- Reduces noise from frame-to-frame variations
- Only tracks with ‚â•5 observations are included in final results

**Assumptions:**

1. **Fixed Camera Perspective**
   - Camera position and angle remain constant
   - Birds at similar distances from camera have comparable scale

2. **Standing Birds**
   - Birds are on the ground (not flying)
   - Body posture is relatively consistent

3. **Linear Relationship**
   - Bounding box area correlates linearly with bird mass
   - Larger bbox ‚Üí heavier bird

4. **Calibration Optional**
   - System provides weight "index" by default (relative measure)
   - Can be calibrated to grams using ground truth data

**Limitations:**

- **Perspective Effects**: Birds closer to camera appear larger
- **Posture Variations**: Crouching vs. standing affects bbox size
- **Occlusions**: Partially occluded birds have smaller bboxes
- **Calibration Required**: For actual weight in grams, must calibrate with scale measurements

**Converting to Grams (Calibration Process):**

1. **Reference Object Calibration**
   ```python
   # Place 10cm √ó 10cm square in camera view
   ref_pixels = measure_reference_object()
   pixels_per_cm = ref_pixels / 10
   ```

2. **Ground Truth Collection**
   ```python
   # Weigh 10+ birds with scale
   true_weights = [2500, 2800, 2650, ...]  # grams
   # Extract weight indices from video
   weight_indices = [2847.3, 3124.8, 2956.1, ...]
   ```

3. **Linear Regression**
   ```python
   from sklearn.linear_model import LinearRegression
   
   model = LinearRegression()
   model.fit(
       np.array(weight_indices).reshape(-1, 1),
       np.array(true_weights)
   )
   
   calibration_factor = model.coef_[0]
   calibration_bias = model.intercept_
   ```

4. **Update System**
   ```python
   weight_estimator = WeightEstimator(
       calibrated=True,
       calibration_factor=0.025,  # example
       calibration_bias=50.0      # example
   )
   ```

## üìö API Documentation

### Endpoints

#### GET /health

Health check endpoint.

**Response:**
```json
{
  "status": "OK",
  "service": "Poultry Monitoring System"
}
```

#### POST /analyze_video

Analyze poultry video for bird counting, tracking, and weight estimation.

**Parameters:**
- `file` (required): Video file (multipart/form-data)
- `fps_sample` (optional): Frame sampling rate (e.g., 5 = process 5 FPS)
- `conf_thresh` (optional): Detection confidence threshold (0-1, default: 0.25)
- `iou_thresh` (optional): IoU threshold for NMS (0-1, default: 0.45)

**Response Structure:**
```json
{
  "counts": [
    {
      "timestamp": 0.0,
      "frame_idx": 0,
      "count": 12
    }
  ],
  "tracks_sample": [
    {
      "track_id": 1,
      "bbox": [100.5, 200.3, 150.8, 280.6],
      "confidence": 0.85,
      "frame_idx": 45,
      "timestamp": 1.5
    }
  ],
  "weight_estimates": [
    {
      "track_id": 1,
      "weight_value": 2847.3,
      "unit": "index",
      "confidence": 0.72,
      "method": "bbox_area_proxy_averaged",
      "num_observations": 45
    }
  ],
  "artifacts": {
    "annotated_video": "/tmp/annotated_20231218_143022.mp4",
    "video_exists": true
  },
  "metadata": {
    "total_frames": 1800,
    "processed_frames": 360,
    "fps": 30.0,
    "effective_fps": 5.0,
    "resolution": [1920, 1080],
    "unique_tracks": 15,
    "avg_bird_count": 12.3,
    "max_bird_count": 18,
    "weight_calibration_needed": true,
    "calibration_requirements": [
      "Place reference object (10cm x 10cm) in view",
      "Weigh 10+ birds with scale",
      "Capture video of weighed birds",
      "Run calibration regression"
    ]
  }
}
```

## üí° Usage Examples

### Example 1: Standard Processing

```bash
curl -X POST "http://localhost:8000/analyze_video" \
  -F "file=@farm_video.mp4" \
  -F "fps_sample=5"
```

### Example 2: High Accuracy (Slower)

```bash
curl -X POST "http://localhost:8000/analyze_video" \
  -F "file=@farm_video.mp4" \
  -F "fps_sample=10" \
  -F "conf_thresh=0.35" \
  -F "iou_thresh=0.50"
```

### Example 3: Fast Processing (Long Videos)

```bash
curl -X POST "http://localhost:8000/analyze_video" \
  -F "file=@long_video.mp4" \
  -F "fps_sample=2" \
  -F "conf_thresh=0.25"
```

### Example 4: Crowded Scenes

```bash
curl -X POST "http://localhost:8000/analyze_video" \
  -F "file=@crowded.mp4" \
  -F "fps_sample=5" \
  -F "conf_thresh=0.20" \
  -F "iou_thresh=0.40"
```

### Example 5: Python Integration

```python
import requests
import json

def analyze_poultry_video(video_path, fps_sample=5):
    """Analyze poultry video and return results"""
    
    with open(video_path, 'rb') as f:
        files = {'file': (video_path, f, 'video/mp4')}
        data = {
            'fps_sample': fps_sample,
            'conf_thresh': 0.25,
            'iou_thresh': 0.45
        }
        
        response = requests.post(
            'http://localhost:8000/analyze_video',
            files=files,
            data=data
        )
        
        if response.status_code == 200:
            return response.json()
        else:
            raise Exception(f"API error: {response.text}")

# Usage
results = analyze_poultry_video('my_video.mp4', fps_sample=5)

print(f"Unique birds: {results['metadata']['unique_tracks']}")
print(f"Avg count: {results['metadata']['avg_bird_count']}")
print(f"Max count: {results['metadata']['max_bird_count']}")

# Save results
with open('results.json', 'w') as f:
    json.dump(results, f, indent=2)
```

## üîß Troubleshooting

### Issue: Too Many False Detections

**Symptoms:** System detects non-bird objects or phantom birds

**Solution:** Increase confidence threshold
```bash
curl -X POST "http://localhost:8000/analyze_video" \
  -F "file=@video.mp4" \
  -F "conf_thresh=0.35"  # Stricter threshold
```

### Issue: Missing Some Birds

**Symptoms:** Known birds not being detected

**Solution:** Decrease confidence threshold
```bash
curl -X POST "http://localhost:8000/analyze_video" \
  -F "file=@video.mp4" \
  -F "conf_thresh=0.15"  # More permissive
```

### Issue: ID Switches During Occlusions

**Symptoms:** Bird IDs change when birds overlap

**Solution:** This requires code modification. Edit `main.py`:
```python
self.tracker = sv.ByteTrack(
    track_activation_threshold=0.25,
    lost_track_buffer=60,  # Increase from 30 to 60
    minimum_matching_threshold=0.8,
    frame_rate=30,
    minimum_consecutive_frames=5
)
```

### Issue: Video Processing Too Slow

**Symptoms:** Takes too long to process videos

**Solutions:**
1. Increase frame sampling:
   ```bash
   curl -F "fps_sample=2"  # Process only 2 FPS
   ```

2. Use GPU acceleration (requires CUDA):
   ```bash
   pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118
   ```

3. Use smaller video resolution (pre-process with ffmpeg):
   ```bash
   ffmpeg -i input.mp4 -vf scale=1280:720 output.mp4
   ```

### Issue: Weight Estimates Seem Incorrect

**Symptoms:** Weight values don't match expectations

**Solution:** System needs calibration for actual grams. Current output is "weight index" (relative measure). See [Implementation Details](#weight-estimation-approach) for calibration process.

### Issue: Import Errors

**Symptoms:** `ModuleNotFoundError` or import failures

**Solution:**
```bash
# Reinstall dependencies
pip uninstall -y ultralytics opencv-python supervision
pip install -r requirements.txt

# Verify installation
python -c "import ultralytics, cv2, supervision; print('OK')"
```

## ‚ö° Performance Optimization

### For Different Scenarios

#### Long Videos (Hours)
```bash
# Sample aggressively for speed
curl -F "fps_sample=2" -F "file=@long_video.mp4"
```

#### Accurate Tracking
```bash
# Higher FPS and stricter thresholds
curl -F "fps_sample=10" -F "conf_thresh=0.35" -F "iou_thresh=0.50"
```

#### Crowded Scenes
```bash
# Lower confidence to catch all birds
curl -F "conf_thresh=0.20" -F "iou_thresh=0.40"
```

### Frame Sampling Guidelines

| Scenario | fps_sample | Rationale |
|----------|-----------|-----------|
| Standard monitoring | 5-10 | Good balance, birds move slowly |
| Long videos (>1 hour) | 2-3 | Efficiency, birds don't change rapidly |
| High accuracy needed | 15-30 | Catch every movement |
| Real-time monitoring | 30 (full FPS) | No sampling, immediate response |

### Hardware Recommendations

**CPU Only (Current Setup):**
- Processing speed: ~5-10 FPS
- 2-minute video: ~5 minutes processing time

**With GPU (CUDA):**
- Processing speed: 50-100 FPS
- 2-minute video: ~30 seconds processing time
- 10x faster than CPU

**Install GPU Support:**
```bash
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118
```

## üìä Example Results

**Input:** 2-minute poultry farm video (3600 frames @ 30 FPS)

**Configuration:**
```bash
fps_sample=5, conf_thresh=0.25, iou_thresh=0.45
```

**Output:**
- **Unique Birds Tracked:** 15
- **Average Count:** 12.3 birds/frame
- **Max Concurrent:** 18 birds
- **Processing Time:** ~5 minutes (on CPU)
- **Annotated Video:** With bounding boxes, IDs, and count overlay

**Weight Estimates (Sample):**

| Track ID | Weight Index | Confidence | Observations | Method |
|----------|--------------|------------|--------------|---------|
| 1 | 2847.3 | 0.72 | 45 | bbox_area_proxy_averaged |
| 2 | 3124.8 | 0.68 | 38 | bbox_area_proxy_averaged |
| 3 | 2956.1 | 0.75 | 52 | bbox_area_proxy_averaged |
| ... | ... | ... | ... | ... |

## üìù License

MIT License - See LICENSE file for details

## ü§ù Support

For issues, questions, or contributions:
- Open an issue on GitHub
- Contact: support@example.com

## üìñ Citation

If you use this system in research, please cite:

```bibtex
@software{poultry_monitor_2024,
  title={Poultry Monitoring System with Computer Vision},
  author={Your Name},
  year={2024},
  url={https://github.com/yourusername/poultry-monitor}
}
```

## üîÑ Version History

- **v1.0.0** (2024-12-18): Initial release
  - YOLOv8 detection
  - ByteTrack tracking
  - Weight estimation
  - REST API
  - Annotated video output
